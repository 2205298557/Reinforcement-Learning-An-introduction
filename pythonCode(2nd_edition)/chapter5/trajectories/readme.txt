The trajectories are solved by Q-learning.
Other on-policy methods are hard to find exact optimal policy.

figure postfix with '-1' is generate with Off-policy Sarsa(\lambda)

It seems like that one step Q-learning is better than Off-policy Sarsa(\lambda).